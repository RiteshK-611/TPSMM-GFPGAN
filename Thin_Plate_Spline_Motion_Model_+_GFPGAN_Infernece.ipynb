{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "05DoBD0NFHp5"
      },
      "source": [
        "# **Thin Plate Spline Motion Model + GFPGAN Infernece**\n",
        "\n",
        "Credit:\n",
        "\n",
        "Thin Plate Spline Motion Model - https://github.com/yoyo-nb/Thin-Plate-Spline-Motion-Model\n",
        "\n",
        "GFPGAN Inference - https://github.com/TencentARC/GFPGAN\n",
        "\n",
        "Thin Plate Spline Motion Model + GFPGAN Infernece - https://github.com/RiteshK-611/TPSMM-GFPGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg20CsXRUKHs"
      },
      "source": [
        "# Setup Thin Plate Spline Motion Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aws1Hlyu9xrT",
        "outputId": "2735e2b4-3089-4b37-dc30-d56b10413cdc"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/RiteshK-611/TPSMM-GFPGAN.git\n",
        "basePath = \"/content/TPSMM-GFPGAN\"\n",
        "%cd {basePath}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3xUkoJaIV7L"
      },
      "outputs": [],
      "source": [
        "tpsmmFolder = 'Thin-Plate-Spline-Motion-Model_main'\n",
        "gfpganFolder = 'GFPGAN_main'\n",
        "tpsmmPath = basePath + '/' + tpsmmFolder\n",
        "gfpganPath = basePath + '/' + gfpganFolder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQoP6nh_FGmH",
        "outputId": "ea0ce774-de08-4a9c-d3f8-dcb7b96f900a"
      },
      "outputs": [],
      "source": [
        "%cd {tpsmmFolder}\n",
        "!mkdir checkpoints\n",
        "# Download Model\n",
        "!wget -c https://cloud.tsinghua.edu.cn/f/da8d61d012014b12a9e4/?dl=1 -O checkpoints/vox.pth.tar\n",
        "#!wget -c https://cloud.tsinghua.edu.cn/f/483ef53650b14ac7ae70/?dl=1 -O checkpoints/ted.pth.tar\n",
        "#!wget -c https://cloud.tsinghua.edu.cn/f/9ec01fa4aaef423c8c02/?dl=1 -O checkpoints/taichi.pth.tar\n",
        "#!wget -c https://cloud.tsinghua.edu.cn/f/cd411b334a2e49cdb1e2/?dl=1 -O checkpoints/mgif.pth.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1YMZxuDHcPe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# edit the config\n",
        "device = torch.device('cuda:0')\n",
        "dataset_name = 'vox' # ['vox', 'taichi', 'ted', 'mgif']\n",
        "output_path = basePath + '/outputs'\n",
        "source_image_path = basePath + '/inputs/source.png'\n",
        "driving_video_path = basePath + '/inputs/driving.mp4'\n",
        "output_video_path = basePath + '/outputs/generated.mp4'\n",
        "config_path = tpsmmPath + '/config/vox-256.yaml'\n",
        "checkpoint_path = tpsmmPath + '/checkpoints/vox.pth.tar'\n",
        "predict_mode = 'relative' # ['standard', 'relative', 'avd']\n",
        "find_best_frame = False # when use the relative mode to animate a face, use 'find_best_frame=True' can get better quality result\n",
        "\n",
        "if not os.path.exists(output_path):\n",
        "  os.makedirs(output_path)\n",
        "\n",
        "pixel = 256 # for vox, taichi and mgif, the resolution is 256*256\n",
        "if(dataset_name == 'ted'): # for ted, the resolution is 384*384\n",
        "    pixel = 384\n",
        "\n",
        "if find_best_frame:\n",
        "  !pip install face_alignment"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "buuCZcGKARnp",
        "outputId": "bce137f0-e080-449d-c133-fc8e2773823c"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import imageio\n",
        "  import imageio_ffmpeg\n",
        "except:\n",
        "  !pip install imageio_ffmpeg\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from skimage.transform import resize\n",
        "from IPython.display import HTML\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "source_image = imageio.imread(source_image_path)\n",
        "reader = imageio.get_reader(driving_video_path)\n",
        "\n",
        "source_image = resize(source_image, (pixel, pixel))[..., :3]\n",
        "\n",
        "fps = reader.get_meta_data()['fps']\n",
        "driving_video = []\n",
        "try:\n",
        "    for im in reader:\n",
        "        driving_video.append(im)\n",
        "except RuntimeError:\n",
        "    pass\n",
        "reader.close()\n",
        "\n",
        "driving_video = [resize(frame, (pixel, pixel))[..., :3] for frame in driving_video]\n",
        "\n",
        "def display(source, driving, generated=None):\n",
        "    fig = plt.figure(figsize=(8 + 4 * (generated is not None), 6))\n",
        "\n",
        "    ims = []\n",
        "    for i in range(len(driving)):\n",
        "        cols = [source]\n",
        "        cols.append(driving[i])\n",
        "        if generated is not None:\n",
        "            cols.append(generated[i])\n",
        "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
        "        plt.axis('off')\n",
        "        ims.append([im])\n",
        "\n",
        "    ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\n",
        "    plt.close()\n",
        "    return ani\n",
        "    \n",
        "\n",
        "HTML(display(source_image, driving_video).to_html5_video())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyX8fH7sCObj"
      },
      "outputs": [],
      "source": [
        "from demo import load_checkpoints\n",
        "inpainting, kp_detector, dense_motion_network, avd_network = load_checkpoints(config_path = config_path, checkpoint_path = checkpoint_path, device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "o84sOb7JCSY2",
        "outputId": "b208a633-d6f7-46b2-a4b5-11c148e80320"
      },
      "outputs": [],
      "source": [
        "from demo import make_animation\n",
        "from skimage import img_as_ubyte\n",
        "\n",
        "if predict_mode=='relative' and find_best_frame:\n",
        "    from demo import find_best_frame as _find\n",
        "    i = _find(source_image, driving_video, device.type=='cpu')\n",
        "    print (\"Best frame: \" + str(i))\n",
        "    driving_forward = driving_video[i:]\n",
        "    driving_backward = driving_video[:(i+1)][::-1]\n",
        "    predictions_forward = make_animation(source_image, driving_forward, inpainting, kp_detector, dense_motion_network, avd_network, device = device, mode = predict_mode)\n",
        "    predictions_backward = make_animation(source_image, driving_backward, inpainting, kp_detector, dense_motion_network, avd_network, device = device, mode = predict_mode)\n",
        "    predictions = predictions_backward[::-1] + predictions_forward[1:]\n",
        "else:\n",
        "    predictions = make_animation(source_image, driving_video, inpainting, kp_detector, dense_motion_network, avd_network, device = device, mode = predict_mode)\n",
        "\n",
        "#save resulting video\n",
        "imageio.mimsave(output_video_path, [img_as_ubyte(frame) for frame in predictions], fps=fps)\n",
        "\n",
        "HTML(display(source_image, driving_video, predictions).to_html5_video())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "rFM-3EoAVMuQ",
        "outputId": "e8073b3a-76e8-4fe5-c3e6-31db6ef431a4"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        " \n",
        "def show_video(video_path, video_width = 600):\n",
        "   \n",
        "  video_file = open(video_path, \"r+b\").read()\n",
        " \n",
        "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "  return HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")\n",
        "\n",
        "# output video\n",
        "show_video(output_video_path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "q2l5iyHIxXm_"
      },
      "source": [
        "# Download Animated Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OifV8jCxTJ2"
      },
      "outputs": [],
      "source": [
        "#Works only on Google Colab\n",
        "from google.colab import files\n",
        "# Download the results\n",
        "files.download(output_video_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC08eR6fUcL0"
      },
      "source": [
        "# Setup GFPGAN Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D75MehOuCqwM",
        "outputId": "88c393db-7d40-4302-a0af-ef8d92bf6c89"
      },
      "outputs": [],
      "source": [
        "%cd ../GFPGAN_main\n",
        "\n",
        "!pip install basicsr\n",
        "!pip install facexlib # We use face detection and face restoration helper in the facexlib package\n",
        "# Install other depencencies\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py develop\n",
        "!pip install realesrgan  # used for enhancing the background (non-face) regions\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -P experiments/pretrained_models #Downloading Model GFPGANv1.4 / GFPGANv1.3 / GFPGANv1.2\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_RNegAcISU2",
        "outputId": "c86e5499-3be1-484d-9f35-6e38a6e96d32"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from os import path\n",
        "\n",
        "import os\n",
        "\n",
        "inputVideoPath = output_path+'/generated.mp4'\n",
        "unProcessedFramesFolderPath = output_path+'/frames'\n",
        "\n",
        "if not os.path.exists(unProcessedFramesFolderPath):\n",
        "  os.makedirs(unProcessedFramesFolderPath)\n",
        "\n",
        "vidcap = cv2.VideoCapture(inputVideoPath)\n",
        "numberOfFrames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
        "print(\"FPS: \", fps, \"Frames: \", numberOfFrames)\n",
        "\n",
        "for frameNumber in tqdm(range(numberOfFrames)):\n",
        "    _,image = vidcap.read()\n",
        "    cv2.imwrite(path.join(unProcessedFramesFolderPath, str(frameNumber).zfill(4)+'.jpg'), image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufZi2mtAF9lG"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6krjfxTJYlu",
        "outputId": "e13b7cf6-de0e-4b25-da4d-6e3eeb08c1af"
      },
      "outputs": [],
      "source": [
        "#Using GFPGAN version 1.4 and Real-ESRGAN for background\n",
        "#If you don't want to enhance background then replace \"realesrgan\" with \"None\" in the below line\n",
        "!python {gfpganFolder}/inference_gfpgan.py -i {unProcessedFramesFolderPath} -o {output_path} -v 1.4 -s 2 --only_center_face --bg_upsampler realesrgan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XibzGPIVJfvP",
        "outputId": "62e144ea-e2d7-4633-e4f5-46360ea9a222"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "restoredFramesPath = output_path + '/restored_imgs/'\n",
        "processedVideoOutputPath = output_path\n",
        "\n",
        "dir_list = os.listdir(restoredFramesPath)\n",
        "dir_list.sort()\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "batch = 0\n",
        "batchSize = 300\n",
        "from tqdm import tqdm\n",
        "for i in tqdm(range(0, len(dir_list), batchSize)):\n",
        "  img_array = []\n",
        "  start, end = i, i+batchSize\n",
        "  print(\"processing \", start, end)\n",
        "  for filename in  tqdm(dir_list[start:end]):\n",
        "      filename = restoredFramesPath+filename;\n",
        "      img = cv2.imread(filename)\n",
        "      if img is None:\n",
        "        continue\n",
        "      height, width, layers = img.shape\n",
        "      size = (width,height)\n",
        "      img_array.append(img)\n",
        "\n",
        "\n",
        "  out = cv2.VideoWriter(processedVideoOutputPath+'/batch_'+str(batch).zfill(4)+'.avi',cv2.VideoWriter_fourcc(*'DIVX'), 30, size)\n",
        "  batch = batch + 1\n",
        " \n",
        "  for i in range(len(img_array)):\n",
        "    out.write(img_array[i])\n",
        "  out.release()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtde28qwpDd6",
        "outputId": "cecf29dd-19c3-4855-9a5b-6bfe2e77bb9d"
      },
      "outputs": [],
      "source": [
        "concatTextFilePath = output_path + \"/concat.txt\"\n",
        "concatTextFile=open(concatTextFilePath,\"w\")\n",
        "for ips in range(batch):\n",
        "  concatTextFile.write(\"file batch_\" + str(ips).zfill(4) + \".avi\\n\")\n",
        "concatTextFile.close()\n",
        "\n",
        "finalVideoOutputPath = output_path + \"/enhanced.mp4\"\n",
        "!ffmpeg -y -f concat -i {concatTextFilePath} -c copy {finalVideoOutputPath} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKH0syu9ZAwV"
      },
      "source": [
        "# Download Enhanced Video\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "lHNHoP8PZJQ7",
        "outputId": "dc4ce164-7d17-410d-dae0-9e07105879b7"
      },
      "outputs": [],
      "source": [
        "#Works only on Google Colab\n",
        "from google.colab import files\n",
        "# Download the results\n",
        "files.download(finalVideoOutputPath)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
